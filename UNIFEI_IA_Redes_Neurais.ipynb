{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNIFEI - IA - Redes Neurais.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KkqjXXdIhUy5"
      ],
      "authorship_tag": "ABX9TyOzKy8DF8dNzsFgcQNu7NOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valerio-unifei/UNIFEI-IA-Aulas/blob/main/UNIFEI_IA_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceEmyCbqTqDG"
      },
      "source": [
        "# Redes Neurais Artificiais (RNA)\n",
        "*Artificial Neural Network (ANN)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujs7h16XUbul"
      },
      "source": [
        "**Definição**\n",
        "\n",
        "Redes neurais artificiais são modelos matemático obtidos dos neurônios naturais. Tem a finalidade de simular seu funcionamento em ambiente computacional de forma a obter sistemas baseados em aprendizagem de máquina (*machine learning*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7wjSCQAhMSD"
      },
      "source": [
        "Como é uma técnica copiada da natureza (neurônio natural), ela é considerada uma abordagem conexionista."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkqjXXdIhUy5"
      },
      "source": [
        "## Treinamento Supervisionado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHlemcDOhekq"
      },
      "source": [
        "O treinamento é obtido através do uso de casos (linhas) organizados (tabela) onde um tutor (valor de saída desejado) é relacionado.\n",
        "\n",
        "O procedimento de treinamento visa a repetição dos casos como entrada nas técnicas e analisa o erro do valor de saída com o tutor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_zFWpg_iDrA"
      },
      "source": [
        "Exemplo: Reproduzir o funcionamento de uma porta E\n",
        "\n",
        "Tabela verdade da porta E, onde:\n",
        "- X são entradas\n",
        "- y é o tutor ou valor esperado da rede\n",
        "\n",
        "|X0|X1|y|\n",
        "|-|-|-----|\n",
        "|0|0|0|\n",
        "|0|1|0|\n",
        "|1|0|0|\n",
        "|1|1|1|\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OfpizliheG8",
        "outputId": "84b595cd-2dca-431d-fd2c-001fe9ad9b80"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[0],[0],[1]])\n",
        "print('X =',X)\n",
        "print('y =',y)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X = [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "y = [[0]\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTbX6zUkbLxx"
      },
      "source": [
        "## Neurônio Artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uktG4CrYbOob"
      },
      "source": [
        "O neurônio artificial é formado das seguintes partes:\n",
        "\n",
        "- entradas (x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>)\n",
        "- entrada Bias (sempre com 1.0)\n",
        "- pesos sinápticos\n",
        "- somador\n",
        "- função de ativação\n",
        "- saída\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*WRG_Re8vGVuHDYigtq2IBA.jpeg\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWaZf7UkR9u8",
        "outputId": "3de4e430-4cc7-485a-86d1-d144e621f412"
      },
      "source": [
        "# --- definindo ---\n",
        "class Perceptron(): # neurônio linear\n",
        "    def __init__(self):\n",
        "      np.random.seed(1)\n",
        "      #pesos sinapticos iniciados aleatoriamente\n",
        "      self.pesos = 2 * np.random.random((2,1))-1\n",
        "\n",
        "    def ativacao(self,x):\n",
        "      return x # ativação linear f(x) = x\n",
        "    \n",
        "    def ativacao_reversa(self,x):\n",
        "      return x # f-1(x) = x\n",
        "\n",
        "    def executar(self, entradas):\n",
        "      entradas = entradas.astype(float)\n",
        "      saida = self.ativacao(np.dot(entradas, self.pesos))\n",
        "      return saida\n",
        "\n",
        "# ---- utilizando ---\n",
        "tico = Perceptron()\n",
        "print('Pesos sinapticos =',tico.pesos)\n",
        "entradas = np.array([0,1])\n",
        "print('Entradas =',entradas)\n",
        "print('Saida =',tico.executar(entradas))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pesos sinapticos = [[-0.16595599]\n",
            " [ 0.44064899]]\n",
            "Entradas = [0 1]\n",
            "Saida = [0.44064899]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvIdCdrIgPqq"
      },
      "source": [
        "Esquisito? Calma, ainda vai piorar!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUVfBKGPx_4p"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvxiKC2IyB7y"
      },
      "source": [
        "Baseado na diferença entre o valor de saída do neurônio e o valor tutor esperado, o ajuste é realizado nos pesos sinápticos (memória da rede neural) que são acrescidos ou reduzidos conforme relação entre o erro e o valor de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiDZC-rQyWhK",
        "outputId": "b5802af6-a484-4a45-8e1c-58c0c799d305"
      },
      "source": [
        "def treina_basico(neuronio, entradas, tutores, iteracoes):\n",
        "  erros = tutores\n",
        "  for iter in range(iteracoes):\n",
        "    saidas = neuronio.executar(entradas)\n",
        "    erros = tutores - saidas\n",
        "    ajustes = np.dot(entradas.T, erros * neuronio.ativacao_reversa(saidas))\n",
        "    neuronio.pesos += ajustes\n",
        "  print('Erro =', erros.sum())\n",
        "\n",
        "tico = Perceptron() \n",
        "treina_basico(tico,X,y,50)\n",
        "print('Pesos sinapticos =',tico.pesos)\n",
        "tico.executar(X)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Erro = -0.632559500993485\n",
            "Pesos sinapticos = [[0.39152884]\n",
            " [0.39152884]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [0.39152884],\n",
              "       [0.39152884],\n",
              "       [0.78305767]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZT_vNW60nNF"
      },
      "source": [
        "Tem um problema, o ajuste brusco nos pesos sinápticos causa oscilação no valor ótimo de funcionamento da rede, portanto precisamos definir uma taxa de aprendizado para que isso não se torne um problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2EEUvVCXxWg"
      },
      "source": [
        "## Neurônios com ativação não linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InTaIpv-dQZZ"
      },
      "source": [
        "<img src=\"https://qph.fs.quoracdn.net/main-qimg-07bc0ec05532caf5ebe8b4c82d0f5ca3\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suR_Fxu6doce",
        "outputId": "1999867a-3284-430d-c969-a399ad877f48"
      },
      "source": [
        "# --- definindo ---\n",
        "class Neuronio(): # neurônio não linear\n",
        "    def __init__(self):\n",
        "      np.random.seed(1)\n",
        "      #pesos sinapticos iniciados aleatoriamente\n",
        "      self.pesos = 2 * np.random.random((2,1))-1\n",
        "\n",
        "    def ativacao(self,x): #sigmoidal\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def ativacao_reversa(self,x):\n",
        "      return x * (1 - x) # motivo de usar a sigmoidal (simples!)\n",
        "    \n",
        "    def executar(self, entradas):\n",
        "      entradas = entradas.astype(float)\n",
        "      saida = self.ativacao(np.dot(entradas, self.pesos))\n",
        "      return saida\n",
        "\n",
        "# ---- utilizando ---\n",
        "teco = Perceptron()\n",
        "print('Pesos sinapticos =',teco.pesos)\n",
        "entradas = np.array([0,1])\n",
        "print('Entradas =',entradas)\n",
        "print('Saida =',teco.executar(entradas))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pesos sinapticos = [[-0.16595599]\n",
            " [ 0.44064899]]\n",
            "Entradas = [0 1]\n",
            "Saida = [0.44064899]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8yH0eyJt2rZ",
        "outputId": "28ea8293-6125-423f-dbe9-7c6eac84b86b"
      },
      "source": [
        "teco = Neuronio() \n",
        "treina_basico(teco,X,y,50)\n",
        "print('Pesos sinapticos =',teco.pesos)\n",
        "teco.executar(X)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Erro = -1.000093408315861\n",
            "Pesos sinapticos = [[-0.01292652]\n",
            " [ 0.01309035]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.50327254],\n",
              "       [0.49676841],\n",
              "       [0.50004096]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f_OYqKiggS4"
      },
      "source": [
        "## Treinamento para redes multi camada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9-TGPh9kAnn"
      },
      "source": [
        "Um rede multi camadas sempre foi um desafio para seu aprendizado no ambiente computacional, pois matematicamente uma rede neural multi camadas com ativação não linear é considerada uma [caixa preta](https://pt.wikipedia.org/wiki/Caixa_preta_(teoria_dos_sistemas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq82E4-ugjyn"
      },
      "source": [
        "<img src=\"https://i2.wp.com/neptune.ai/wp-content/uploads/Backpropagation-architecture.png?resize=768%2C643&ssl=1\">\n",
        "\n",
        "Rede Neural Artificial com 4 camadas:\n",
        "- Camada de entrada ( ~ número de colunas da tabela)\n",
        "- Camada oculta 1\n",
        "- Camada oculta 2\n",
        "- Camada de saída ( ~ classes para identificar)\n",
        "\n",
        "\n",
        "**Metodologia Clássica:** Retro propagação de erro.\n",
        "\n",
        "<img src=\"https://i1.wp.com/neptune.ai/wp-content/uploads/Backpropagation-passes-architecture.png?resize=768%2C732&ssl=1\">\n",
        "\n",
        "O erro entre o tutor e a resposta da rede trafega da camada de saída para a entrada através da função inversa de ativação e os pesos sinápticos das entradas de cada neurônio da rede.\n",
        "\n",
        "<img src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/Backpropagation-prediction.png?resize=1024%2C218&ssl=1\">\n",
        "\n",
        "Como funciona a retro propagação de erro:\n",
        "1. A rede tem seus pesos sinápticos inicializados aleatóriamente;\n",
        "2. É inserido o 1o caso (linha 1) e a saída da rede é obtida;\n",
        "3. Erro entre a saída da rede e o tutor (valor esperado);\n",
        "4. O erro é previsto na entrada da camada de saída pela **função de ativação inversa**; \n",
        "5. O erro previsto é distribuído para as entradas através do peso sináptico;\n",
        "6. A 2a camada oculta recebe o erro previsto nas saídas de seus neurônios;\n",
        "7. Novamente o erro é previsto nas entradas pela **função de ativação inversa**;\n",
        "8. Os pesos sinápticos dos neurônios da 2a camada oculta distribuiem o erro para suas entradas;\n",
        "9. A 1a camada oculta recebe o erro previsto nas saídas de seus neurônios;\n",
        "10. Novamente o erro é previsto nas entradas pela **função de ativação inversa**;\n",
        "11. Os pesos sinápticos dos neurônios da 1a camada oculta distribuiem o erro para suas entradas;\n",
        "12. A camada de entrada recebe o erro previsto nas saídas de seus neurônios;\n",
        "13. Novamente o erro é previsto nas entradas pela **função de ativação inversa**;\n",
        "14. Todos os pesos sinápticos são ajustados pelo erro previsto sobre sua respectiva entrada em todas as camadas...\n",
        "\n",
        "Problemas neste processo de aprendizado:\n",
        " - lentidão\n",
        " - mínimos locais de erro ao invés de mínimo global\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9X3TBj-weIN"
      },
      "source": [
        "## Problema da separação dos espaços\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CHPIvVhwk8A"
      },
      "source": [
        "<img src=\"https://d3i71xaburhd42.cloudfront.net/7e73bffddc02223a8037e07da898cb194a64a619/9-Figure5-1.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fddrBuwye0jg"
      },
      "source": [
        "# Redes Multi Camada\n",
        "\n",
        "Multi-Layer Perceptron (MLP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlsf9HNAcdxM"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Mohamed-Zahran-16/publication/303875065/figure/fig4/AS:371118507610123@1465492955561/A-hypothetical-example-of-Multilayer-Perceptron-Network.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD-4RR9ufQdE"
      },
      "source": [
        "## MLP para Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tNrGp5Xf4hp"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_jgXe-TfTg9"
      },
      "source": [
        "**Classificação**:\n",
        "\n",
        "Identificar um tutor discreto, identificado por classes.\n",
        "\n",
        "- 0 - Falso\n",
        "- 1 - Verdadeiro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhmVUs_BwlRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6782ea12-1f87-43c4-a2c9-d2e84fe0cdbb"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Ou-exclusivo\n",
        "X = [[0,0],[0,1],[1,0],[1,1]]\n",
        "y = [0,1,1,0]\n",
        "\n",
        "funcoes = ['identity','logistic','tanh','relu']\n",
        "\n",
        "for activation in funcoes:\n",
        "  rna = MLPClassifier(activation=activation, solver='lbfgs',hidden_layer_sizes=(4,))\n",
        "  #treinamento\n",
        "  rna.fit(X,y)\n",
        "\n",
        "  print('--- ativação =',activation, ' ---')\n",
        "  print('camadas =',rna.n_layers_)\n",
        "  print('acurácia =', rna.score(X,y))\n",
        "  print('y_previsto =',rna.predict(X))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- ativação = identity  ---\n",
            "camadas = 3\n",
            "acurácia = 0.5\n",
            "y_previsto = [1 1 1 1]\n",
            "--- ativação = logistic  ---\n",
            "camadas = 3\n",
            "acurácia = 1.0\n",
            "y_previsto = [0 1 1 0]\n",
            "--- ativação = tanh  ---\n",
            "camadas = 3\n",
            "acurácia = 1.0\n",
            "y_previsto = [0 1 1 0]\n",
            "--- ativação = relu  ---\n",
            "camadas = 3\n",
            "acurácia = 0.75\n",
            "y_previsto = [0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjrKW7OOfteL"
      },
      "source": [
        "**Informação:** Por que a ativação linear deu o pior resultado?\n",
        "\n",
        "Motivo uma rede MLP com ativação linear em todas as camadas pode ser simplificada para apenas UM neurônio de ativação linear. \n",
        "\n",
        "Portanto, no problema de separação dos espaços, o comportamento do ou-exclusivo não pode ser classificado por apenas 1 camada (neste caso 1 neurônio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4obIKn8Ay3JM"
      },
      "source": [
        "### Tipos de Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbWHIPPvzcaZ"
      },
      "source": [
        "O MLP treina usando Stochastic Gradient Descent , Adam ou L-BFGS.\n",
        "- https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
        "- https://arxiv.org/abs/1412.6980\n",
        "- https://en.wikipedia.org/wiki/Limited-memory_BFGS\n",
        "\n",
        "O solucionador padrão 'adam' funciona muito bem em conjuntos de dados relativamente grandes (com milhares de amostras de treinamento ou mais) em termos de tempo de treinamento e pontuação de validação. \n",
        "\n",
        "Para pequenos conjuntos de dados, entretanto, 'lbfgs' pode convergir mais rápido e ter um desempenho melhor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrfdkMKQgUx4",
        "outputId": "94af28ea-fb2d-467e-cc8d-0ceb76a92e34"
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "#https://pt.wikipedia.org/wiki/Conjunto_de_dados_flor_Iris\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print('Casos/Linhas =',len(X),' Classes =',set(y))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Casos/Linhas = 150  Classes = {0, 1, 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CZ25Tn31uLp",
        "outputId": "a518fed5-e7f5-4e13-fedd-aeb5ae208df4"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "funcoes = ['identity','logistic','tanh','relu']\n",
        "otimizadores = ['lbfgs', 'sgd', 'adam']\n",
        "\n",
        "for solver in otimizadores:\n",
        "  for activation in funcoes:\n",
        "    rna = MLPClassifier(activation=activation, solver=solver,hidden_layer_sizes=(4,))\n",
        "    #treinamento\n",
        "    rna.fit(X,y)\n",
        "\n",
        "    print(' otimizador =',solver,\n",
        "          ' ativação =',activation, \n",
        "          ' acurácia =', rna.score(X,y))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " otimizador = lbfgs  ativação = identity  acurácia = 0.9866666666666667\n",
            " otimizador = lbfgs  ativação = logistic  acurácia = 0.9933333333333333\n",
            " otimizador = lbfgs  ativação = tanh  acurácia = 0.9933333333333333\n",
            " otimizador = lbfgs  ativação = relu  acurácia = 0.3333333333333333\n",
            " otimizador = sgd  ativação = identity  acurácia = 0.36\n",
            " otimizador = sgd  ativação = logistic  acurácia = 0.3333333333333333\n",
            " otimizador = sgd  ativação = tanh  acurácia = 0.5133333333333333\n",
            " otimizador = sgd  ativação = relu  acurácia = 0.8533333333333334\n",
            " otimizador = adam  ativação = identity  acurácia = 0.6466666666666666\n",
            " otimizador = adam  ativação = logistic  acurácia = 0.66\n",
            " otimizador = adam  ativação = tanh  acurácia = 0.64\n",
            " otimizador = adam  ativação = relu  acurácia = 0.3333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}